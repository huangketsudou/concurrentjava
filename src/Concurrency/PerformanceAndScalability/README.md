### 性能与可伸缩性

#### 性能

使用多线程具有额外的开销：线程协调（加锁，触发信号以及内存同步），增加的上下文切换，线程的创建与销毁，线程调度。

#### Andahl定律

对于包含N个处理器的机器，F为必须串行的比例，最高的加速比为：

speedup<=1/(F+(1-F)/N)

N为无穷时，最大加速比为1/F

#### 线程数的选择：

对于最佳的线程数设置：（（线程等待时间（I/O操作执行时间）+线程CPU时间（线程实际运行时间））/线程CPU时间）*CPU数目

任何使用共享队列来执行线程任务分配的方法都会在线程中引入一个串行部分，例如LinkedBlockingQueue的take方法从其中取数据就是串行的。

通过修改同步队列的实现可以提高性能，例如concurrentLinkedQueue的性能就优于一般的同步队列。原因是concurrentLinkedQueue采用了非阻塞队列算法，而一般的同步队列采用了单个锁来维护队列状态。

应用场景：锁分解技术(把一个锁分解为两个锁)以及锁分段技术(把一个锁分解为多个锁)。在第11章中提到。

#### 线程引入的开销

为了提高性能而引入的线程，并行带来的性能必须大于并发导致的开销。

##### 上下文切换

 上下文切换指的是内核（操作系统的核心）在CPU上对进程或者线程进行切换。上下文切换过程中的信息被保存在进程控制块（PCB-Process Control Block）中。PCB又被称作切换桢（SwitchFrame）。上下文切换的信息会一直被保存在CPU的内存中，直到被再次使用。 

把前一个任务的 CPU 上下文（也就是 CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下文到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运行新任务。而这些保存下来的上下文，会存储在系统内核中，并在任务重新调度执行时再次加载进来。这样就能保证任务原来的状态不受影响，让任务看起来还是连续运行。

三个切换类型：

进程上下文切换

线程上下文切换

中断上下文切换

当可运行的线程大于CPU数量的时候，操作系统最终会将某个正在执行的线程调度出来，使其他的线程能够使用CPU，这将会导致一次上下文切换。

当线程由于等待某个资源而被阻塞时，JVM通常会将线程挂起，并允许其被交换出去，如果线程频繁发生阻塞，那么将无法使用完整的时间片，从而导致发生频繁的上下文切换。

##### 内存同步

sychronized和volatile提供的可见性能中具有一些特殊指令，即内存栅栏，内存栅栏可以刷新缓存，使缓存无效，刷新新硬件的写缓存，并停止执行管道。内存栅栏也可能会对性能造成影响，因为会抑制一些编译器的优化。

现代的JVM会通过一些操作实现锁去除操作，例如对下面的代码

```java
public String getStoogeNames(){
	List<String> stooges = new Vector<String>();
	stooges.add("Moe");
	stooges.add("Larrry");
	stooges.add("Curly");
	return stooges.toString();
}
```

如上如果有多个线程在执行该方法，由于stooges是方法的局部变量，不会再线程中共享，且其中存储的字符串也不会被共享，因此JVM会直接去掉vector中的锁。

##### 阻塞

JVM实现阻塞的方式为自旋等待或者操作系统挂起而阻塞的等待。使用场合：

等待时间短：采用自旋方式

等待时间长：采用线程挂起的方式

JVM一般用的是挂起的方式

#### 减少锁的竞争

串行操作会降低可伸缩性，上下文切换也会降低性能。对可伸缩性的最主要威胁就是独占方式的资源锁。其存在两种竞争的可能：锁的请求频率，每次持有锁的时间

降低发生竞争可能性的方式包括：

##### 缩小锁的范围（快进快出）

一种有效的方式是尽可能地缩短锁地持有时间，包括将与锁无关的代码移出同步代码块，以及可能被阻塞的操作（如：I/O操作）

但是同步代码块也不能够太小，否则JVM在执行粗粒度化操作时，会将分解的同步块又合并起来，导致额外的开销。

##### 减小锁粒度

降低线程请求锁的频率，可通过锁分解和锁分段等技术来实现，这些技术将采用多个相互独立的锁来保护独立的状态变量，但是使用的锁越多，死锁的可能性越大。

###### 锁分解

如果一个锁需要保护多个相互独立的状态变量，那么可以将这个锁分解为多个锁，且每个锁只保护一个状态变量。

###### 锁分段

把激烈竞争的锁分解为两个锁时，可能存在激烈的竞争，为了进一步提高性能，可以将锁分解技术进一步扩展为一组独立对象上的锁进行分解，将其称为锁分段。**ConcurrentHashMap使用了一个包含16个锁的数组，每个锁保护所有散列桶的1/16，其中第N个散列桶由第（N mod 16）个锁来保护。如果散列函数具有合理的分布，且关键字分布均匀，那么锁的请求可以减少到1/16，因此ConcurrentHashMap可以支持最多16个并发写入器**

**锁分段劣势**：

与采用单个锁来实现独占访问相比，获取多个锁来实现独占访问将更难而且开销更高。通常执行一个操作需要获得一个锁，但是在某些情况下需要加锁整个容器，例如当ConcurrentHashMap需要扩展映射范围，以及重新计算键值的散列值要分布到更大的桶时，就需要获取分段锁集合中的全部锁。

##### 避免热点域

当操作请求多个变量时，锁的粒度将会很难降低，这是在性能与可伸缩性之间相互制衡的结果，有些常见优化措施，可以将一些反复计算的结果缓存起来，导致引入热点域。ConcurrentHashMap中size函数就与热点域相关

##### 检测CPU利用率

#### 减少上下文切换的开销

当任务在运行与阻塞两个状态之间切换就相当于发生了一次上下文切换。



